---
title: "Dzień 3 - Curve fitting"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
---
<style type="text/css">
.title {
  display: none;
}

.table {
    width:70%;
}

#getting-started img {
  margin-right: 10px;
}

</style>



# Curve fitting

"Curve fitting" (dopasowanie krzywej) to zadanie sprowadzająca się do szukania najbardziej dopasowanego modelu. 

W przykładach ograniczymy się do jednej zmiennej objaśniającej, jednak można to w dosyć prosty sposób zastosować również przy kilku zmiennych objaśniających.

```{r}
x <- c(32,64,96,118,126,144,152.5,158)
y <- c(99.5,104.8,108.5,100,86,64,35.3,15)
plot(x,y, pch=20)
```

Stwórzmy kilka modeli i zrób wykresy teoretycznych wartości z modelu:

```{r}
model1  <- lm(y~x)
model2 <- lm(y~poly(x,2,raw=TRUE))
model3 <- lm(y~poly(x,3,raw=TRUE))
model4 <- lm(y~poly(x,4,raw=TRUE))
x.axis <- seq(30,160, length=50)
plot(x,y,pch=20,ylim=c(0,150))
lines(x.axis, predict(model1,data.frame(x=x.axis)), col="red")
lines(x.axis, predict(model2,data.frame(x=x.axis)), col="green")
lines(x.axis, predict(model3,data.frame(x=x.axis)), col="blue")
lines(x.axis, predict(model4,data.frame(x=x.axis)), col="purple")
```

Sprawdźmy $R^2$:

```{r}
summary(model1)$r.squared
summary(model2)$r.squared
summary(model3)$r.squared
summary(model4)$r.squared
```

Sprawdźmy skorygowane $\overline{R}^2$:

```{r}
summary(model1)$adj.r.squared
summary(model2)$adj.r.squared
summary(model3)$adj.r.squared
summary(model4)$adj.r.squared
```

Co nam pokaże `anova`? 

```{r}
anova(model1,model2,model4,model3)
```

Dodajmy model nieliniowy.

```{r}
model5<-nls(y~poly(x,5,raw=TRUE)%*% coef, start = list(coef = c(a = 1, b = 2, c=2, d=4, e=2)))
anova(model4,model5)
```

Musimy porównywać w większości wypadkóW modele "tego samego typu":

```{r}
model6<-nls(y~poly(x,4,raw=TRUE)%*% coef, start = list(coef = c(a = 1, b = 2, c=2, d=1)))
anova(model6, model5)
```

Jak zatem porównywać? Pierwsza opcja to ręczne liczenie $R^2$.

```{r}
ym<-mean(y)
yh<-fitted(model4)
ssm<-sum((yh-ym)^2)
sst<-sum((y-ym)^2)
r2<-ssm/sst
r2
yh<-fitted(model5)
ssm<-sum((yh-ym)^2)
sst<-sum((y-ym)^2)
r2<-ssm/sst
r2
yh<-fitted(model6)
ssm<-sum((yh-ym)^2)
sst<-sum((y-ym)^2)
r2<-ssm/sst
r2
```

Zobaczmy wykresy.

```{r}
plot(x,y,pch=20,ylim=c(0,150))
lines(x.axis, predict(model4,data.frame(x=x.axis)), col="red")
lines(x.axis, predict(model5,data.frame(x=x.axis)), col="blue")
lines(x.axis, predict(model6,data.frame(x=x.axis)), col="green")
```

Jak to mierzyć? Możemy sprawdzić tzw. kryterium informacyjne Akaikego (Akaike Information Criterion) - [link](https://pl.wikipedia.org/wiki/Kryterium_informacyjne_Akaikego).

```{r}
AIC(model1)
AIC(model2)
AIC(model3)
AIC(model4)
AIC(model5)
AIC(model6)
```


## Ćwiczenie

1. Wygenerujmy sobie dane:

```{r}
x<-seq(10,50,1)
y<-100/x+rnorm(1,sd=2)
```

Poszukaj najlepszego modelu.


